{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/importlib/__init__.py:126: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/cudf/utils/_ptxcompiler.py:64: UserWarning: Error getting driver and runtime versions:\n",
      "\n",
      "stdout:\n",
      "\n",
      "\n",
      "\n",
      "stderr:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 4, in <module>\n",
      "  File \"/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/numba_cuda/numba/cuda/cudadrv/driver.py\", line 272, in __getattr__\n",
      "    raise CudaSupportError(\"Error at driver init: \\n%s:\" %\n",
      "numba.cuda.cudadrv.error.CudaSupportError: Error at driver init: \n",
      "\n",
      "CUDA driver library cannot be found.\n",
      "If you are sure that a CUDA driver is installed,\n",
      "try setting environment variable NUMBA_CUDA_DRIVER\n",
      "with the file path of the CUDA driver shared library.\n",
      ":\n",
      "\n",
      "\n",
      "Not patching Numba\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/cudf/utils/gpu_utils.py:62: UserWarning: Failed to dlopen libcuda.so.1\n",
      "  warnings.warn(str(e))\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "\n",
    "dask.config.set({\"dataframe.query-planning\": False})\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.extend(['../../scripts','../../scripts/xenium'])\n",
    "import readwrite\n",
    "import preprocessing\n",
    "\n",
    "cfg = readwrite.config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg paths\n",
    "xenium_dir = Path(cfg['xenium_processed_data_dir'])\n",
    "xenium_raw_data_dir = Path(cfg['xenium_raw_data_dir'])\n",
    "results_dir = Path(cfg['results_dir'])\n",
    "\n",
    "# Segmentation, mapping paths\n",
    "dir_segmentations = {\n",
    "    dir_segmentation.name: (dir_segmentation)\n",
    "    for dir_segmentation in xenium_dir.iterdir()\n",
    "}\n",
    "\n",
    "# Read resegmentations and RCTD\n",
    "xenium_paths = {}\n",
    "umaps = {}\n",
    "cc_paths = []\n",
    "\n",
    "for segmentation in (segmentations := xenium_dir.iterdir()):\n",
    "    for condition in (conditions := segmentation.iterdir()): \n",
    "        for panel in (panels := condition.iterdir()):\n",
    "            for donor in (donors := panel.iterdir()):\n",
    "                for sample in (samples := donor.iterdir()):\n",
    "                    \n",
    "                    k = (segmentation.stem,condition.stem,panel.stem,donor.stem,sample.stem)\n",
    "                    sample_path = sample / \"normalised_results/outs\"\n",
    "                    name = '/'.join(k)\n",
    "\n",
    "                    xenium_paths[k] = sample_path\n",
    "\n",
    "\n",
    "xenium_levels = ('segmentation','condition','panel','donor','sample')\n",
    "# ads = readwrite.read_xenium_samples(xenium_paths,anndata_only=True,transcripts=False,sample_name_as_key=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read umaps\n",
    "umaps = {}\n",
    "for k,sample_path in xenium_paths.items():\n",
    "    file = sample_path / 'analysis/umap/gene_expression_2_components/projection.csv'\n",
    "    if file.exists():\n",
    "        umaps[k] = pd.read_csv(file,index_col=0)\n",
    "\n",
    "# Read RCTD\n",
    "rctd = {}\n",
    "for k,path in xenium_paths.items():\n",
    "\n",
    "    if (references := path.parents[1] / \"cell_type_annotation/reference_based\").exists():\n",
    "            \n",
    "        rctd[k] = {}\n",
    "\n",
    "        for reference in (references := path.parents[1] / \"cell_type_annotation/reference_based\").iterdir():\n",
    "            if reference.stem != 'matched_reference':\n",
    "                continue\n",
    "            for method in (methods := reference.iterdir()):\n",
    "                if method.stem !='rctd_class_aware':\n",
    "                    continue\n",
    "                for level in (levels := method.iterdir()):\n",
    "                    if color.stem != 'Level2':\n",
    "                        continue\n",
    "                    cell_type_annotation_file = color / 'single_cell/labels.csv'\n",
    "                    if cell_type_annotation_file.exists():\n",
    "                        rctd[k][reference.stem,method.stem,color.stem] = pd.read_parquet(cell_type_annotation_file).set_index('cell_id').iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Define the parameters\n",
    "references = ['matched_reference','external_reference']\n",
    "methods = ['rctd']\n",
    "levels = ['Level2']\n",
    "\n",
    "# Preprocess and collect all data for consistent palette\n",
    "df = {}\n",
    "for k in umaps:\n",
    "    if k in rctd and len(rctd[k]):\n",
    "        rctd_df = pd.DataFrame(rctd[k])\n",
    "        rctd_df.columns = [col for col in rctd_df.columns]\n",
    "        df[k] = pd.concat((umaps[k], rctd_df), axis=1).dropna()\n",
    "\n",
    "df = pd.concat(df).reset_index()\n",
    "df.columns = (*xenium_levels,'cell_id', 'UMAP1', 'UMAP2', *df.columns[8:])\n",
    "\n",
    "# Extract unique condition and panel combinations\n",
    "segmentation_condition_panel = df[['segmentation','condition', 'panel']].drop_duplicates()\n",
    "\n",
    "# Plotting\n",
    "for reference in references:\n",
    "    for method in methods:\n",
    "        for level in levels:\n",
    "            params = (reference, method, level)\n",
    "\n",
    "            unique_labels = np.unique(df[params])\n",
    "            palette = dict(zip(unique_labels,sc.pl.palettes.default_28))\n",
    "            legend_handles = [mpatches.Patch(color=color, label=label) for label, color in palette.items()]\n",
    "\n",
    "            for segmentation, condition, panel in segmentation_condition_panel.values:\n",
    "                print(f\"Segmentation: {segmentation}, condition: {condition}, Panel: {panel}, Method: {method}, Reference: {reference}, Level: {level}\")\n",
    "\n",
    "                # Filter data for the current condition and panel\n",
    "                subset = df.query(f\"segmentation == '{segmentation}' and condition == '{condition}' and panel == '{panel}'\")\n",
    "\n",
    "                # Calculate the number of rows and columns dynamically\n",
    "                n_plots = subset['sample'].nunique()\n",
    "                n_cols = min(4, n_plots)\n",
    "                n_rows = int(np.ceil(n_plots / n_cols))\n",
    "\n",
    "                f, axs = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "                axs = axs.flat if n_plots > 1 else [axs]\n",
    "\n",
    "                for i, (sample, group) in enumerate(subset.groupby('sample')):\n",
    "                    ax = axs[i]\n",
    "                    sns.scatterplot(data=group, x=\"UMAP1\", y=\"UMAP2\", s=1, alpha=.5,\n",
    "                                    hue=params, ax=ax, palette=palette, legend=False)\n",
    "                    ax.set_title(sample)\n",
    "                    ax.xaxis.set_ticks([])\n",
    "                    ax.yaxis.set_ticks([])\n",
    "                    sns.despine()\n",
    "\n",
    "                # Hide unused subplots\n",
    "                for j in range(n_plots, len(axs)):\n",
    "                    f.delaxes(axs[j])\n",
    "\n",
    "                plt.suptitle(f\"Segmentation: {segmentation}, condition: {condition}, Panel: {panel}, Method: {method}, Reference: {reference}, Level: {level}\")\n",
    "                f.legend(handles=legend_handles, \n",
    "                         loc='center left', \n",
    "                         bbox_to_anchor=(1, 0.5), \n",
    "                         title=', '.join(params), \n",
    "                         frameon=False)\n",
    "                plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "                plt.savefig(cfg['figures_dir'] + f\"embed_donor/umap_{segmentation}_{condition=}_{panel=}_{method=}_{reference=}_{level=}.png\", dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per panel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/std_seurat_analysis/proseg_expected/NSCLC/5k/0PSV/0PSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/std_seurat_analysis/proseg_expected/NSCLC/5k/1G73/1G73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/std_seurat_analysis/proseg_expected/NSCLC/5k/1GDD/1GDD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/std_seurat_analysis/proseg_expected/NSCLC/5k/1GAC/1GAC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/std_seurat_analysis/proseg_expected/NSCLC/5k/1GQ9/1GQ9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/std_seurat_analysis/proseg_expected/NSCLC/5k/1GVD/1GVD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 out of 289 genes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from pathlib import Path\n",
    "\n",
    "# Params\n",
    "n_comps = 50\n",
    "n_neighbors = 50\n",
    "min_dist = 0.3\n",
    "metric = 'cosine'\n",
    "\n",
    "# Set up argument parser\n",
    "# Access the arguments\n",
    "segmentation = '10x_5um'\n",
    "condition = 'NSCLC'\n",
    "panel = '5k'\n",
    "normalisation_method = \"sctransform\"  # fix this for now, even for sctransfrom args.normalisation_method\n",
    "layer = 'scale_data'\n",
    "\n",
    "k = (segmentation,condition,panel,normalisation_method)\n",
    "name = '/'.join(k)\n",
    "\n",
    "panel = Path(f'/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/std_seurat_analysis/{segmentation}/{condition}/{panel}')\n",
    "genes = pd.read_csv('/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/markers/Xenium_hLung_v1_metadata.csv')['Gene'].tolist()\n",
    "\n",
    "\n",
    "# vars\n",
    "xenium_levels = [\"segmentation\", \"condition\", \"panel\", \"donor\", \"sample\", \"cell_id\"]\n",
    "segmentation = panel.parents[1]\n",
    "condition = panel.parents[0]\n",
    "\n",
    "# load umap\n",
    "ads = {}\n",
    "for donor in (donors := panel.iterdir()):\n",
    "    for sample in (samples := donor.iterdir()):\n",
    "        print(sample)\n",
    "\n",
    "        k = (segmentation, condition, panel.stem, donor.stem, sample.stem)\n",
    "        sample_counts_path = sample / f\"{normalisation_method}/normalised_counts/{layer}.parquet\"\n",
    "        sample_idx_path = sample / f\"{normalisation_method}/normalised_counts/cells.parquet\"\n",
    "\n",
    "        ads[k] = sc.AnnData(pd.read_parquet(sample_counts_path))\n",
    "        if layer != \"scale_data\":  # no need to sparsify scale_data which is dense\n",
    "            ads[k].X = scipy.sparse.csr_matrix(ads[k].X)\n",
    "        ads[k].obs_names = pd.read_parquet(sample_idx_path).iloc[:, 0]\n",
    "\n",
    "\n",
    "# concatenate\n",
    "xenium_levels = [\"segmentation\", \"condition\", \"panel\", \"donor\", \"sample\"]\n",
    "for k in ads.keys():\n",
    "    for i, lvl in enumerate(xenium_levels):\n",
    "        ads[k].obs[lvl] = k[i]\n",
    "ad_merge = sc.concat(ads)\n",
    "\n",
    "# subset to genes\n",
    "if len(genes):\n",
    "    genes_found = [\n",
    "        g\n",
    "        for g in ad_merge.var_names \n",
    "        if (g in genes) or (g.replace(\".\", \"-\") in genes)  # possible seurat renaming\n",
    "    ]\n",
    "\n",
    "    print(f\"Found {len(genes_found)} out of {len(genes)} genes.\")\n",
    "    ad_merge = ad_merge[:, genes_found].copy()\n",
    "\n",
    "# preprocess\n",
    "# preprocessing.preprocess(\n",
    "#     ad_merge,\n",
    "#     normalize=False,\n",
    "#     log1p=False,\n",
    "#     scale=\"none\",\n",
    "#     n_comps=n_comps,\n",
    "#     metric=metric,\n",
    "#     min_dist=min_dist,\n",
    "#     n_neighbors=n_neighbors,\n",
    "#     pca=True,\n",
    "#     umap=True,\n",
    "#     save_raw=False,\n",
    "#     min_counts=None,\n",
    "#     min_genes=None,\n",
    "#     max_counts=None,\n",
    "#     max_genes=None,\n",
    "#     min_cells=None,\n",
    "# )\n",
    "\n",
    "# # save\n",
    "# df_umap = pd.DataFrame(ad_merge.obsm[\"X_umap\"], index=ad_merge.obs_names, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "# df_umap[xenium_levels] = ad_merge.obs[xenium_levels]\n",
    "\n",
    "# df_umap.to_parquet(out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = cfg['results_dir']\n",
    "palette_dir = Path(cfg['xenium_metadata_dir'])\n",
    "cell_type_annotation_dir = Path(cfg['xenium_cell_type_annotation_dir'])\n",
    "\n",
    "# Params\n",
    "n_comps = 50\n",
    "n_neighbors = 50\n",
    "min_dist = 0.3\n",
    "metric = 'cosine'\n",
    "\n",
    "# Set up argument parser\n",
    "# Access the arguments\n",
    "segmentation = 'proseg_expected'\n",
    "condition = 'breast'\n",
    "panel = 'breast'\n",
    "normalisation_method = \"lognorm\"  # fix this for now, even for sctransfrom args.normalisation_method\n",
    "layer = 'data'\n",
    "\n",
    "k = (segmentation,condition,panel,normalisation_method)\n",
    "name = '/'.join(k)\n",
    "\n",
    "panel = Path(f'/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/std_seurat_analysis/{segmentation}/{condition}/{panel}')\n",
    "embed_file = Path(results_dir) / f'embed_panel/{name}/umap_{layer}_{n_comps=}_{n_neighbors=}_{min_dist=}_{metric}.parquet'\n",
    "reference = 'matched_reference_combo'\n",
    "method = 'rctd_class_aware'\n",
    "color = 'Level2'\n",
    "cell_type_palette = palette_dir / 'col_palette_cell_types.csv'\n",
    "panel_palette = palette_dir / 'col_palette_panel.csv'\n",
    "sample_palette = palette_dir / 'col_palette_donor.csv'\n",
    "\n",
    "\n",
    "if color == \"sample\":\n",
    "    palette = pd.read_csv(sample_palette, index_col=0).iloc[:, 0]\n",
    "elif color == \"panel\":\n",
    "    palette = pd.read_csv(panel_palette, index_col=0).iloc[:, 0]\n",
    "else:\n",
    "    palette = pd.read_csv(cell_type_palette)[[color, f\"cols_{color}\"]].drop_duplicates().set_index(color).squeeze()\n",
    "\n",
    "\n",
    "# vars\n",
    "xenium_levels = [\"segmentation\", \"condition\", \"panel\", \"donor\", \"sample\", \"cell_id\"]\n",
    "segmentation = panel.parents[1]\n",
    "condition = panel.parents[0]\n",
    "\n",
    "# load umap\n",
    "obs = pd.read_parquet(embed_file)\n",
    "obs[\"cell_id\"] = obs.index\n",
    "\n",
    "\n",
    "if color == \"sample\":\n",
    "    # plot sample as color, no need to load annotations\n",
    "    df = obs\n",
    "    params = color\n",
    "    title = f\"Segmentation: {segmentation.stem}, condition: {condition.stem}, Panel: {panel.stem}\"\n",
    "\n",
    "else:\n",
    "    # read cell type annotation\n",
    "    annot = {}\n",
    "    for donor in (donors := panel.iterdir()):\n",
    "        for sample in (samples := donor.iterdir()):\n",
    "            k = (\n",
    "                segmentation.stem,\n",
    "                condition.stem,\n",
    "                panel.stem,\n",
    "                donor.stem,\n",
    "                sample.stem,\n",
    "            )\n",
    "            name = \"/\".join(k)\n",
    "\n",
    "            annot[k] = {}\n",
    "            annot_file = (\n",
    "                cell_type_annotation_dir\n",
    "                / name\n",
    "                / f\"{normalisation_method}/reference_based/{reference}/{method}/{color}/single_cell/labels.parquet\"\n",
    "            )\n",
    "            # if annot_file.exists():\n",
    "            annot[k][reference, method, color] = pd.read_parquet(annot_file).set_index(\"cell_id\").iloc[:, 0]\n",
    "\n",
    "    # merge annotations\n",
    "    df_annot = {}\n",
    "    for k in annot:\n",
    "        if len(annot[k]):\n",
    "            df_ = pd.DataFrame(annot[k])\n",
    "            df_.columns = [col for col in df_.columns]\n",
    "            df_annot[k] = df_\n",
    "    df_annot = pd.concat(df_annot)\n",
    "    df_annot.index.names = xenium_levels\n",
    "    df_annot = df_annot.reset_index()\n",
    "\n",
    "    # merge umap and cell type annotations\n",
    "    df = pd.merge(obs, df_annot, on=xenium_levels, how=\"inner\")\n",
    "\n",
    "    params = (reference, method, color)\n",
    "    title = f\"Segmentation: {segmentation.stem}, condition: {condition.stem}, Panel: {panel.stem}\\n Method: {method}, Reference: {reference}\"\n",
    "\n",
    "\n",
    "# plotting params, palette\n",
    "unique_labels = np.unique(df[params].dropna())\n",
    "palette = {u: palette[u] for u in unique_labels}\n",
    "legend_handles = [\n",
    "    mpatches.Patch(color=color, label=label) for label, color in palette.items()\n",
    "]\n",
    "\n",
    "# print(\n",
    "#     f\"Segmentation: {segmentation.stem}, condition: {condition.stem}, Panel: {panel.stem}, Method: {method}, Reference: {reference}, Level: {level}\"\n",
    "# )\n",
    "\n",
    "\n",
    "# plot\n",
    "f = plt.figure(figsize=(12, 10))\n",
    "ax = plt.subplot()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"UMAP1\",\n",
    "    y=\"UMAP2\",\n",
    "    s=0.1,\n",
    "    alpha=0.5,\n",
    "    hue=params,\n",
    "    ax=ax,\n",
    "    palette=palette,\n",
    "    legend=False,\n",
    ")\n",
    "ax.xaxis.set_ticks([])\n",
    "ax.yaxis.set_ticks([])\n",
    "sns.despine()\n",
    "\n",
    "plt.title(title)\n",
    "f.legend(\n",
    "    handles=legend_handles,\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    title=params if isinstance(params, str) else \", \".join(params),\n",
    "    frameon=False,\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "# plt.savefig(out_file, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per panel facetted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = cfg['results_dir']\n",
    "palette_dir = Path(cfg['xenium_metadata_dir'])\n",
    "\n",
    "# Params\n",
    "n_comps = 50\n",
    "n_neighbors = 50\n",
    "min_dist = 0.3\n",
    "metric = 'cosine'\n",
    "\n",
    "# Set up argument parser\n",
    "# Access the arguments\n",
    "segmentation = 'proseg'\n",
    "condition = 'NSCLC'\n",
    "panel = 'lung'\n",
    "k = (segmentation,condition,panel)\n",
    "name = '/'.join(k)\n",
    "\n",
    "panel = Path(f'/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/segmentation/{segmentation}/{condition}/{panel}')\n",
    "embed_file = Path(results_dir) / f'embed_panel/{name}/umap_{n_comps=}_{n_neighbors=}_{min_dist=}_{metric}.parquet'\n",
    "reference = 'matched_reference'\n",
    "method = 'rctd_class_aware'\n",
    "level = 'Level2'\n",
    "cell_type_palette = palette_dir / 'col_palette_cell_types.csv'\n",
    "panel_palette = palette_dir / 'col_palette_panel.csv'\n",
    "sample_palette = palette_dir / 'col_palette_donor.csv'\n",
    "\n",
    "if level == \"sample\":\n",
    "    palette = pd.read_csv(sample_palette, index_col=0).iloc[:, 0]\n",
    "elif level == \"panel\":\n",
    "    palette = pd.read_csv(panel_palette, index_col=0).iloc[:, 0]\n",
    "else:\n",
    "    palette = pd.read_csv(cell_type_palette).set_index(level)[f'cols_{level}'].drop_duplicates()\n",
    "\n",
    "\n",
    "# vars\n",
    "xenium_levels = [\"segmentation\", \"condition\", \"panel\", \"donor\", \"sample\", \"cell_id\"]\n",
    "segmentation = panel.parents[1]\n",
    "condition = panel.parents[0]\n",
    "\n",
    "# load umap\n",
    "obs = pd.read_parquet(embed_file)\n",
    "obs[\"cell_id\"] = obs.index\n",
    "\n",
    "\n",
    "if level == \"sample\":\n",
    "    # plot sample as color, no need to load annotations\n",
    "    df = obs\n",
    "    params = level\n",
    "    title = (\n",
    "        f\"Segmentation: {segmentation.stem}, condition: {condition.stem}, Panel: {panel.stem}\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # read cell type annotation\n",
    "    annot = {}\n",
    "    for donor in (donors := panel.iterdir()):\n",
    "        for sample in (samples := donor.iterdir()):\n",
    "            k = (\n",
    "                segmentation.stem,\n",
    "                condition.stem,\n",
    "                panel.stem,\n",
    "                donor.stem,\n",
    "                sample.stem,\n",
    "            )\n",
    "            name = \"/\".join(k)\n",
    "\n",
    "            annot[k] = {}\n",
    "            annot_file = (\n",
    "                sample\n",
    "                / f\"cell_type_annotation/reference_based/{reference}/{method}/{level}/single_cell/labels.parquet\"\n",
    "            )\n",
    "            if annot_file.exists():\n",
    "                annot[k][reference, method, level] = (\n",
    "                    pd.read_parquet(annot_file).set_index(\"cell_id\").iloc[:, 0]\n",
    "                )\n",
    "\n",
    "    # merge annotations\n",
    "    df_annot = {}\n",
    "    for k in annot:\n",
    "        if len(annot[k]):\n",
    "            df_ = pd.DataFrame(annot[k])\n",
    "            df_.columns = [col for col in df_.columns]\n",
    "            df_annot[k] = df_\n",
    "    df_annot = pd.concat(df_annot)\n",
    "    df_annot.index.names = xenium_levels\n",
    "    df_annot = df_annot.reset_index()\n",
    "\n",
    "    # merge umap and cell type annotations\n",
    "    df = pd.merge(obs, df_annot, on=xenium_levels, how=\"inner\")\n",
    "\n",
    "    params = (reference, method, level)\n",
    "    title = f\"Segmentation: {segmentation.stem}, condition: {condition.stem}, Panel: {panel.stem}\\n Method: {method}, Reference: {reference}, Level: {level}\"\n",
    "\n",
    "\n",
    "# plotting params, palette\n",
    "unique_labels = np.unique(df[params].dropna())\n",
    "palette = {u: palette[u] for u in unique_labels}\n",
    "legend_handles = [\n",
    "    mpatches.Patch(color=color, label=label) for label, color in palette.items()\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Segmentation: {segmentation.stem}, condition: {condition.stem}, Panel: {panel.stem}, Method: {method}, Reference: {reference}, Level: {level}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the number of rows and columns dynamically\n",
    "n_plots = df['sample'].nunique()\n",
    "n_cols = min(4, n_plots)\n",
    "n_rows = int(np.ceil(n_plots / n_cols))\n",
    "\n",
    "f, axs = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "axs = axs.flat if n_plots > 1 else [axs]\n",
    "\n",
    "for i, (sample, group) in enumerate(df.groupby('sample')):\n",
    "    ax = axs[i]\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=df,\n",
    "        x=\"UMAP1\",\n",
    "        y=\"UMAP2\",\n",
    "        s=0.1,\n",
    "        alpha=0.5,\n",
    "        hue=params,\n",
    "        ax=ax,\n",
    "        palette=palette,\n",
    "        legend=False,\n",
    "    )\n",
    "    ax.xaxis.set_ticks([])\n",
    "    ax.yaxis.set_ticks([])\n",
    "    sns.despine()\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(n_plots, len(axs)):\n",
    "    f.delaxes(axs[j])\n",
    "\n",
    "\n",
    "    plt.title(title)\n",
    "    f.legend(\n",
    "        handles=legend_handles,\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(1, 0.5),\n",
    "        title=params if isinstance(params, str) else \", \".join(params),\n",
    "        frameon=False,\n",
    "    )\n",
    "    \n",
    "plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "# plt.savefig(out_file, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
