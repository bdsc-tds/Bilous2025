{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/cudf/utils/_ptxcompiler.py:64: UserWarning: Error getting driver and runtime versions:\n",
      "\n",
      "stdout:\n",
      "\n",
      "\n",
      "\n",
      "stderr:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 4, in <module>\n",
      "  File \"/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py\", line 295, in __getattr__\n",
      "    raise CudaSupportError(\"Error at driver init: \\n%s:\" %\n",
      "numba.cuda.cudadrv.error.CudaSupportError: Error at driver init: \n",
      "\n",
      "CUDA driver library cannot be found.\n",
      "If you are sure that a CUDA driver is installed,\n",
      "try setting environment variable NUMBA_CUDA_DRIVER\n",
      "with the file path of the CUDA driver shared library.\n",
      ":\n",
      "\n",
      "\n",
      "Not patching Numba\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/cudf/utils/gpu_utils.py:62: UserWarning: Failed to dlopen libcuda.so.1\n",
      "  warnings.warn(str(e))\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/numba/core/decorators.py:246: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/utils.py:429: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/utils.py:429: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/utils.py:429: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/anndata/utils.py:429: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import spatialdata_io\n",
    "import spatialdata\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sys\n",
    "sys.path.extend(['../../scripts','../../scripts/xenium'])\n",
    "import coexpression\n",
    "import readwrite\n",
    "cfg = readwrite.config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNTS_PATH = \"/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/segmentation/10x_0um/breast/breast/0OE1/0OE1/normalised_results/outs/cell_feature_matrix.h5\"\n",
    "# TRANSCRIPT_PATH = \"/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/segmentation/10x_0um/breast/breast/0OE1/0OE1/normalised_results/outs/transcripts.parquet\"\n",
    "# RCTD_PATH = \"/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/segmentation/10x_0um/breast/breast/0OE1/0OE1/cell_type_annotation/reference_based/matched_reference/rctd/Level1/single_cell/labels.csv\"\n",
    "\n",
    "# ad = sc.read_10x_h5(COUNTS_PATH)\n",
    "# transcripts = pd.read_parquet(TRANSCRIPT_PATH)\n",
    "# obs = pd.read_csv(RCTD_PATH,index_col=0)\n",
    "\n",
    "\n",
    "# print(len(ad),len(transcripts['cell_id'].unique())-1)\n",
    "# X2 = transcripts.groupby(['feature_name', 'cell_id']).size().unstack(fill_value=0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/results/coexpression/proseg_v1/breast/breast/1FYB/1FYB/coexpression_conditional_30.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 58\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     55\u001b[0m                                 cc_paths\u001b[38;5;241m.\u001b[39mappend((k, method, target_count))\n\u001b[0;32m---> 58\u001b[0m CC, pos_rate \u001b[38;5;241m=\u001b[39m \u001b[43mreadwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_coexpression_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcc_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m xenium_levels \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegmentation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpanel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdonor\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# ads = readwrite.read_xenium_donors(xenium_paths,anndata_only=True,transcripts=False,donor_name_as_key=False)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# ads = pd.Series(ads.values(),\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#                 index=pd.Index(ads.keys(),name = xenium_levels),\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#                 dtype=object).sort_index()\u001b[39;00m\n",
      "File \u001b[0;32m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/workflow/notebooks/xenium/../../scripts/readwrite.py:461\u001b[0m, in \u001b[0;36mread_coexpression_files\u001b[0;34m(cc_paths, results_dir)\u001b[0m\n\u001b[1;32m    459\u001b[0m pos_rate \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[0;32m--> 461\u001b[0m     method, target_count, cc, pr \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     k \u001b[38;5;241m=\u001b[39m cc_paths[futures\u001b[38;5;241m.\u001b[39mindex(future)][\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    464\u001b[0m     ]  \u001b[38;5;66;03m# Retrieve the `k` corresponding to this future\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m CC:\n",
      "File \u001b[0;32m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/workflow/notebooks/xenium/../../scripts/readwrite.py:426\u001b[0m, in \u001b[0;36mread_coexpression_file\u001b[0;34m(k, method, target_count, results_dir)\u001b[0m\n\u001b[1;32m    417\u001b[0m out_file_coexpr \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m     results_dir\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoexpression/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(k)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/coexpression_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m )\n\u001b[1;32m    421\u001b[0m out_file_pos_rate \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    422\u001b[0m     results_dir\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoexpression/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(k)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/positivity_rate_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m )\n\u001b[0;32m--> 426\u001b[0m cc \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_file_coexpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m pos_rate \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(out_file_pos_rate)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method, target_count, cc, pos_rate\n",
      "File \u001b[0;32m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/results/coexpression/proseg_v1/breast/breast/1FYB/1FYB/coexpression_conditional_30.parquet'"
     ]
    }
   ],
   "source": [
    "# cfg paths\n",
    "xenium_dir = Path(cfg['xenium_processed_data_dir'])\n",
    "xenium_raw_data_dir = Path(cfg['xenium_raw_data_dir'])\n",
    "results_dir = Path(cfg['results_dir'])\n",
    "\n",
    "# Segmentation, mapping paths\n",
    "dir_segmentations = {\n",
    "    dir_segmentation.name: (dir_segmentation)\n",
    "    for dir_segmentation in xenium_dir.iterdir()\n",
    "}\n",
    "# dir_segmentations['default'] = xenium_raw_data_dir\n",
    "\n",
    "# Params\n",
    "# SEGMENTATIONS = list(dir_segmentations.keys())\n",
    "# conditions = [p.stem for p in xenium_raw_data_dir.iterdir() if p.is_dir()]\n",
    "# conditions_PANELS = {condition: [p.stem for p in (xenium_raw_data_dir / condition).iterdir()] for condition in conditions}\n",
    "# conditions_donors = {(condition,panel): \n",
    "#                         [sample.stem \n",
    "#                         for donor in (xenium_raw_data_dir / condition / panel).iterdir()\n",
    "#                         for sample in donor.iterdir()\n",
    "#                         if 'corrupt' not in sample.name and 'output' not in sample.name and sample.is_dir()] \n",
    "#                     for condition in conditions \n",
    "#                     for panel in conditions_PANELS[condition]}\n",
    "\n",
    "\n",
    "# Read resegmentations and RCTD\n",
    "# Coexpression params\n",
    "methods = ['conditional','jaccard','pearson','spearman']\n",
    "target_counts = [30,50,200]\n",
    "\n",
    "xenium_paths = {}\n",
    "umaps = {}\n",
    "cc_paths = []\n",
    "\n",
    "for segmentation in (segmentations := xenium_dir.iterdir()):\n",
    "    for condition in (conditions := segmentation.iterdir()): \n",
    "        for panel in (panels := condition.iterdir()):\n",
    "            for donor in (donors := panel.iterdir()):\n",
    "                for sample in (samples := donor.iterdir()):\n",
    "                    \n",
    "                    k = (segmentation.stem,condition.stem,panel.stem,donor.stem,sample.stem)\n",
    "                    sample_path = sample / \"normalised_results/outs\"\n",
    "                    name = '/'.join(k)\n",
    "\n",
    "                    xenium_paths[k] = sample_path\n",
    "                    if (sample_path / 'analysis/umap/gene_expression_2_components/projection.csv').exists():\n",
    "                        umaps[k] = pd.read_csv(sample_path / 'analysis/umap/gene_expression_2_components/projection.csv',index_col=0)\n",
    "\n",
    "                    if sample_path.exists():\n",
    "\n",
    "                        for method in methods:\n",
    "                            for target_count in target_counts:\n",
    "                                if target_count > 50 and panel.stem != '5k':\n",
    "                                    continue\n",
    "                                cc_paths.append((k, method, target_count))\n",
    "\n",
    "\n",
    "CC, pos_rate = readwrite.read_coexpression_files(cc_paths, results_dir)\n",
    "xenium_levels = ('segmentation','condition','panel','donor','sample')\n",
    "# ads = readwrite.read_xenium_donors(xenium_paths,anndata_only=True,transcripts=False,donor_name_as_key=False)\n",
    "# ads = pd.Series(ads.values(),\n",
    "#                 index=pd.Index(ads.keys(),name = xenium_levels),\n",
    "#                 dtype=object).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name,f in all_files.items():\n",
    "#     if pathlib.Path(cfg['figures_dir']+f'xenium/QC/{name}.png').exists():\n",
    "#         print('skipping',name,f)\n",
    "#         continue\n",
    "#     else:\n",
    "#         # try:\n",
    "#         # sd = readwrite.read_xenium_donors({name:f},anndata_only=False,transcripts=True)[name]\n",
    "#         QC(sd,name,cfg['figures_dir']+f'xenium/QC/{name}.png')\n",
    "#         %xdel sd\n",
    "#         # except:\n",
    "#         #     print('failed',name,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed_donors = ['1G4Y', '1G11']\n",
    "# for name,f in all_files.items():\n",
    "#     if name.split('-')[2] in failed_donors:\n",
    "#         print(name)\n",
    "#         sd = readwrite.read_xenium({name:f},anndata_only=False,transcripts=True)[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coexpression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find spurious genes as in proseg paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coexpression params\n",
    "min_positivity_rate = 0.01\n",
    "cc_cutoff = 1.5\n",
    "log2 = False\n",
    "ref_segmentation = '10x_0um'\n",
    "\n",
    "CCdiff = {}\n",
    "spurious_gene_pairs = {}\n",
    "for k in CC.keys():\n",
    "    if k[0] == ref_segmentation:\n",
    "        continue\n",
    "\n",
    "    CCdiff[k] = {}\n",
    "    spurious_gene_pairs[k] = {}\n",
    "    for m in methods:\n",
    "        for t in target_counts:\n",
    "            k_ref = (ref_segmentation,*k[1:])\n",
    "\n",
    "            (CCdiff[k][m,t], \n",
    "            spurious_gene_pairs[k][m,t]) = coexpression.compare_segmentations(\n",
    "                                CC_ref_seg = CC[k_ref][m,t], \n",
    "                                CC_other_seg = CC[k][m,t], \n",
    "                                pos_rate_ref_seg=pos_rate[k_ref][m,t], \n",
    "                                pos_rate_other_seg=pos_rate[k][m,t], \n",
    "                                min_positivity_rate=min_positivity_rate, \n",
    "                                cc_cutoff = cc_cutoff,\n",
    "                                method=m, log2=log2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "method = 'jaccard'\n",
    "target_count = 50\n",
    "ref_oversegmentation = '10x_15um'\n",
    "log2 = True\n",
    "keys = pd.DataFrame(CCdiff.keys(),columns=xenium_levels)\n",
    "condition_panels = keys[['condition','panel']].drop_duplicates()\n",
    "\n",
    "for method in methods:\n",
    "    for target_count in target_counts:\n",
    "        for condition,panel in condition_panels.values:\n",
    "            data = []\n",
    "            for _,k in keys.iterrows():\n",
    "                if (condition == k['condition'] and panel ==  k['panel']):\n",
    "                    \n",
    "                    k_ref_over = (ref_oversegmentation,*k[1:])\n",
    "\n",
    "                    mat = CCdiff[*k][method,target_count].replace(1.,np.nan)\n",
    "                    if log2:\n",
    "                        with warnings.catch_warnings(action=\"ignore\"):\n",
    "                            mat = np.log2(mat)\n",
    "                        \n",
    "                    i = spurious_gene_pairs[k_ref_over][method,target_count][:,0]\n",
    "                    j = spurious_gene_pairs[k_ref_over][method,target_count][:,1]\n",
    "                    flat_values = mat.values[mat.index.get_indexer(i), mat.columns.get_indexer(j)] \n",
    "                    data.extend(np.hstack((np.tile(k,(len(i),1)),flat_values[:,None])))\n",
    "\n",
    "            # Convert to DataFrame for easier plotting\n",
    "            df = pd.DataFrame(data, columns=xenium_levels+('log2 relative coexpression',))\n",
    "            df['log2 relative coexpression']=df['log2 relative coexpression'].astype(float)\n",
    "\n",
    "            # Create joint boxplot\n",
    "            sns.set(style=\"ticks\",palette='colorblind')\n",
    "            plt.figure(figsize=(6, df['sample'].nunique()))\n",
    "            g = sns.violinplot(data=df, x=\"log2 relative coexpression\", y=\"sample\", hue='segmentation', cut=0, width=.8,inner='quart')\n",
    "\n",
    "            plt.title(f\"{condition=} {panel=} {method=} {target_count=}\")\n",
    "            # plt.axvline(0,c='k',linestyle='-',zorder=0,alpha=.3)\n",
    "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), title='Segmentation', frameon=False)\n",
    "            sns.despine(offset=10, trim=True)\n",
    "            plt.gca().xaxis.grid(True) \n",
    "            plt.savefig(cfg['figures_dir'] + f\"{condition=} {panel=} {method=} {target_count=}.png\",dpi=300,bbox_inches='tight')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes_idx = sd1.var_names.isin(u_markers_panel)\n",
    "pos_nuc_markers = pos_nuc[:,marker_genes_idx]\n",
    "\n",
    "CC_cells = coexpression.coexpression_cells(pos_nuc)\n",
    "CC_cells_sum = coexpression.coexpression_cells_score(CC_cells, marker_genes_idx)\n",
    "plt.hist(CC_cells_sum,bins=50)\n",
    "plt.show()\n",
    "\n",
    "sd1.obs.loc[mask_nuc,'CC_cells_sum'] = CC_cells_sum\n",
    "\n",
    "sc.set_figure_params(figsize=(15,15))\n",
    "sc.pl.spatial(sd1[mask_nuc],spot_size=15,color='CC_cells_sum',cmap='viridis',vmax=50)\n",
    "sc.pl.spatial(sd1[mask_nuc],spot_size=15,color='total_counts',cmap='viridis',vmax=150)\n",
    "\n",
    "plt.scatter(sd1[mask_nuc].obs['total_counts'],sd1[mask_nuc].obs['CC_cells_sum'],alpha=.5)\n",
    "np.corrcoef(sd1[mask_nuc].obs['total_counts'],sd1[mask_nuc].obs['CC_cells_sum'])[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find coexpressed and spurious genes scRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = sc.read(cfg['scrnaseq_processed_flex_full_zurich_h5ad'])\n",
    "ad_panel = ad[:,[g for g in sd1.var_names if g in ad.var_names]]\n",
    "\n",
    "# compute CC\n",
    "CCnuc_found = CCnuc.loc[ad_panel.var_names,ad_panel.var_names]\n",
    "CCnuc_sc, Xnuc_downdonord_sc, pos_nuc_sc, pos_rate_nuc_sc, mask_nuc_sc = coexpression.coexpression(ad_panel,return_all=1)\n",
    "CCdiff_sc, spurious_gene_pairs_sc = coexpression.compare_segmentations(pos_rate_nuc_sc, pos_rate_nuc, CCnuc_sc, CCnuc_found, min_positivity_rate=0.01,cc_cutoff = 2)\n",
    "spurious_genes_idx_sc = np.unique(np.where(spurious_gene_pairs_sc))\n",
    "spurious_genes_sc = ad_panel.var_names[spurious_genes_idx_sc]\n",
    "spurious_genes_markers_sc = df_markers_panel.loc[df_markers_panel['canonical'].isin(spurious_genes_sc),'canonical'].unique()\n",
    "\n",
    "print(len(spurious_genes_markers_sc), 'marker genes /', len(spurious_genes_sc),'spurious panel genes found')\n",
    "\n",
    "# plot\n",
    "sns.set(font_scale=.8)\n",
    "# sns.clustermap(CCnuc.loc[spurious_genes,spurious_genes],yticklabels=True,xticklabels=True,figsize=(10,10))\n",
    "sns.clustermap(CCdiff_sc.loc[spurious_genes_markers_sc,spurious_genes_markers_sc],\n",
    "    yticklabels=True,xticklabels=True,figsize=(15,15),vmin=None,vmax=4,cmap='RdBu_r',center=1)\n",
    "plt.show()\n",
    "\n",
    "df_ct_markers_cc_nuc_sc, df_cc_melt_nuc_sc = coexpression.coexpression_by_cell_type(CCnuc_sc,spurious_genes_markers_sc,df_markers_panel)\n",
    "sns.heatmap(df_ct_markers_cc,cmap='Purples')\n",
    "plt.show()\n",
    "\n",
    "df_ct_markers_cc_diff_sc, df_cc_melt_diff_sc = coexpression.coexpression_by_cell_type(CCdiff_sc,spurious_genes_markers_sc,df_markers_panel)\n",
    "sns.heatmap(df_ct_markers_cc,cmap='RdBu_r',center=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "df_markers_panel_ct = df_markers_panel.set_index(\"canonical\")\n",
    "df_cc_melt = df_cc_melt_nuc_sc.copy()\n",
    "df_cc_melt['ct_genei'] = ''\n",
    "df_cc_melt['ct_genej'] = ''\n",
    "for i, row in df_cc_melt.iterrows():\n",
    "    ct_genei = df_markers_panel_ct.loc[row[\"genei\"], \"index\"]\n",
    "    ct_genej = df_markers_panel_ct.loc[row[\"genej\"], \"index\"]\n",
    "\n",
    "    if isinstance(ct_genei, str):\n",
    "        ct_genei = [ct_genei]\n",
    "    if isinstance(ct_genej, str):\n",
    "        ct_genej = [ct_genej]\n",
    "    df_cc_melt.loc[df_cc_melt[\"genei\"] == row[\"genei\"],'ct_genei'] = ' & '.join(ct_genei) \n",
    "    df_cc_melt.loc[df_cc_melt[\"genej\"] == row[\"genej\"],'ct_genej'] = ' & '.join(ct_genej)\n",
    "\n",
    "display(df_cc_melt[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coexpression based on computational marker genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate genes coexpression from scRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doublets\n",
    "# result = pyreadr.read_r('/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/dbuszta/meso/processed_data/new_data/doublets_by_donor.rds')[None]\n",
    "\n",
    "# load data\n",
    "ad_sc = sc.read_h5ad(cfg['scrnaseq_processed_flex_full_zurich_h5ad'])\n",
    "# ad_sc.obs['doublet_status'] = result.iloc[:,0]\n",
    "# ad_sc = ad_sc[ad_sc.obs['doublet_status']=='singlet']\n",
    "# ad_sc.obs = ad_sc.obs.join(pd.read_csv(cfg['results_dir']+'annotation/cell_type_annotation.csv',index_col=0))\n",
    "\n",
    "# filter to xenium genes\n",
    "xenium_panel_genes = pd.read_csv(cfg['data_dir']+'xenium_chuvio_panel_genes.csv',index_col=0)['0']\n",
    "ad_sc_panel = ad_sc[:,ad_sc.var_names.isin(xenium_panel_genes)]\n",
    "\n",
    "CT_KEY = 'cell_type_harmonized_level2_consensus'\n",
    "u_cell_types = ad_sc_panel.obs[CT_KEY].unique()\n",
    "\n",
    "# get df with max fraction for each cell type\n",
    "(df_fraction,df_difference, \n",
    "df_max_difference) = coexpression.find_markers(ad_sc_panel, CT_KEY, threshold_fraction = 1., threshold_diff = 0.)\n",
    "df_difference_sorted = df_difference[df_difference.max().sort_values().index]\n",
    "\n",
    "# get df with thresholded max fraction for each cell type\n",
    "(_,df_difference_thresholded, \n",
    " df_max_difference_thresholded) = coexpression.find_markers(ad_sc_panel, CT_KEY, threshold_fraction = 0.01, threshold_diff = 0.25)\n",
    "df_difference_thresholded_sorted = df_difference_thresholded[df_difference_thresholded.max().sort_values().index]\n",
    "\n",
    "for df_difference_sorted_, df_max_difference_ in zip([df_difference_sorted,df_difference_thresholded_sorted],\n",
    "                                                     [df_max_difference,df_max_difference_thresholded]):\n",
    "\n",
    "    ### Boxplots\n",
    "    plt.figure(figsize=(8,30))\n",
    "\n",
    "    flierprops = dict(marker='o', markersize=1, linestyle='none', markerfacecolor='black')\n",
    "    ax = sns.boxplot(data=df_difference_sorted_, orient='h', flierprops=flierprops)\n",
    "\n",
    "    # Loop over columns to find and highlight max fliers\n",
    "    for i, col in enumerate(df_difference_sorted_.columns):\n",
    "        data = df_difference_sorted_[col]\n",
    "        max_val = data.max()  # Find maximum value in the column\n",
    "        ax.scatter(max_val,i, color='red', edgecolor='black', zorder=5, s=20)\n",
    "\n",
    "    plt.title(\"Difference in % of cells expressing\")\n",
    "    plt.show()\n",
    "\n",
    "    ### Heatmap\n",
    "    sns.heatmap(df_max_difference_)\n",
    "\n",
    "# Define markers\n",
    "df_markers_scores = pd.DataFrame(index=ad_sc_panel.var_names,columns=u_cell_types)\n",
    "\n",
    "for cti in u_cell_types:\n",
    "    cti_columns = df_difference_thresholded.columns.str.split(\"_\").str[0] == cti\n",
    "\n",
    "    df_markers_scores[cti] = df_difference_thresholded.loc[:,cti_columns].mean(1)\n",
    "\n",
    "ct_markers = {}\n",
    "for ct in u_cell_types:\n",
    "    ct_scores = df_markers_scores[ct].sort_values(ascending=False).dropna()\n",
    "    markers_ = list(ct_scores[(ct_scores>0.)][:10].index)\n",
    "\n",
    "    if len(markers_) > 0:\n",
    "        ct_markers[ct] = markers_\n",
    "\n",
    "df_markers_computational = pd.DataFrame([\n",
    "    {\"index\": k, \"canonical\": v}\n",
    "    for k, values in ct_markers.items()\n",
    "    for v in values\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coexpression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rctd_weights_key = 'weights_FLEX_original'\n",
    "\n",
    "normalized_entropy_computational = {}\n",
    "CC_computational = {}\n",
    "CC_cells_sum_normalized_computational = {}\n",
    "\n",
    "for segmentation in SEGMENTATIONS:\n",
    "\n",
    "    normalized_entropy_computational[segmentation] = {}\n",
    "    CC_computational[segmentation] = {}\n",
    "    CC_cells_sum_normalized_computational[segmentation] = {}\n",
    "        \n",
    "    for k,ad_ in ads[segmentation].items():\n",
    "        print(k)\n",
    "\n",
    "        ad = ad_[ad_.uns[rctd_weights_key].index]\n",
    "\n",
    "        ### Entropy\n",
    "        W = ad.uns[rctd_weights_key].copy()\n",
    "        W[W<0] = 0.\n",
    "        W = sklearn.preprocessing.normalize(W,axis=0,norm='l1')\n",
    "        normalized_entropy_computational[segmentation][k] = scipy.stats.entropy(W,axis=1)/np.log(W.shape[1])\n",
    "\n",
    "        ### Coexpression\n",
    "        # compute CC\n",
    "        CC, X_downdonord, pos, pos_rate, mask = coexpression.coexpression(ad,target_count=30,method='jaccard')\n",
    "        CC_computational[segmentation][k] = CC\n",
    "\n",
    "        # load markers\n",
    "        # df_markers_computational_panel = df_markers_computational[df_markers_computational['canonical'].isin(ad.var_names)]\n",
    "        # u_markers_panel = df_markers_computational_panel['canonical'].unique()\n",
    "        # marker_genes_idx = ad.var_names.isin(u_markers_panel)\n",
    "        # print(len(u_markers_panel), 'marker genes /', ad.shape[1],'panel genes found')\n",
    "\n",
    "        # df_ct_markers_cc = coexpression.coexpression_by_cell_type(CC,u_markers_panel,df_markers_computational_panel)\n",
    "#         CC_cells = coexpression.coexpression_cells(pos)\n",
    "#         CC_cells_sum = coexpression.coexpression_cells_score(CC_cells, marker_genes_idx)\n",
    "#         CC_cells_sum_normalized_computational[k] = np.array(CC_cells_sum)/(marker_genes_idx.sum()**2)\n",
    "#         break\n",
    "\n",
    "# palette = {'singlet':'green','doublet_certain':'blue','doublet_uncertain':'orange','reject':'red'}\n",
    "# for segmentation in SEGMENTATIONS[:1]:\n",
    "#     for k,ad_ in ads[segmentation].items():\n",
    "#         ad = ad_[ad_.uns[rctd_weights_key].index]\n",
    "\n",
    "#         g = sns.jointplot(x=normalized_entropy_computational[k], y=CC_cells_sum_normalized_computational[k], palette=palette,hue=ad.obs['spot_class_FLEX_original'],kind=\"scatter\", height=5,s=8,alpha=.3)\n",
    "#         g.set_axis_labels(f'{k} - normalized RCTD weights normalized entropy', f'{k} - normalized coexpression score')\n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rctd_weights_key = 'weights_FLEX_original'\n",
    "\n",
    "# Define a function for processing one (segmentation, k) pair\n",
    "def process_task(segmentation, k, ad_, rctd_weights_key):\n",
    "    print(f\"Processing {segmentation}, {k}\")\n",
    "\n",
    "    # Filter data\n",
    "    ad = ad_[ad_.uns[rctd_weights_key].index]\n",
    "\n",
    "    # Entropy computation\n",
    "    W = ad.uns[rctd_weights_key].copy()\n",
    "    W[W < 0] = 0.0\n",
    "    W = sklearn.preprocessing.normalize(W, axis=0, norm='l1')\n",
    "    normalized_entropy = scipy.stats.entropy(W, axis=1) / np.log(W.shape[1])\n",
    "\n",
    "    # Coexpression computation\n",
    "    CC, X_downdonord, pos, pos_rate, mask = coexpression.coexpression(ad, target_count=30, method='jaccard')\n",
    "\n",
    "    return segmentation, k, normalized_entropy, CC\n",
    "\n",
    "# Prepare the tasks\n",
    "tasks = []\n",
    "for segmentation in SEGMENTATIONS:\n",
    "    for k, ad_ in ads[segmentation].items():\n",
    "        tasks.append((segmentation, k, ad_, rctd_weights_key))\n",
    "\n",
    "# Run tasks in parallel\n",
    "results = Parallel(n_jobs=-1, backend=\"loky\")(\n",
    "    delayed(process_task)(segmentation, k, ad_, rctd_weights_key) for segmentation, k, ad_, rctd_weights_key in tasks\n",
    ")\n",
    "\n",
    "# Collect results\n",
    "normalized_entropy_computational = {seg: {} for seg in SEGMENTATIONS}\n",
    "CC_computational = {seg: {} for seg in SEGMENTATIONS}\n",
    "\n",
    "for segmentation, k, entropy, CC in results:\n",
    "    normalized_entropy_computational[segmentation][k] = entropy\n",
    "    CC_computational[segmentation][k] = CC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor = '16MD_run14'\n",
    "coexpr_scores = pd.DataFrame()\n",
    "normalized_entropy_computational_scores = pd.DataFrame()\n",
    "for segmentation,CC_segmentations in CC_computational.items():\n",
    "    for donor, CC_donor in CC_segmentations.items():\n",
    "        coexpr_scores.loc[segmentation,donor] = CC_donor.values[np.triu_indices_from(CC_donor,1)].sum()\n",
    "        normalized_entropy_computational_scores.loc[segmentation,donor] = normalized_entropy_computational[segmentation][donor].sum()\n",
    "\n",
    "sns.clustermap(coexpr_scores.fillna(coexpr_scores.mean()),figsize=(10,5),cmap='Reds')\n",
    "\n",
    "coexpr_scores_norm = coexpr_scores.fillna(coexpr_scores.mean())\n",
    "sns.clustermap(coexpr_scores_norm/coexpr_scores_norm.max(),figsize=(10,5),cmap='Reds')\n",
    "\n",
    "sns.clustermap(normalized_entropy_computational_scores,figsize=(10,5),cmap='Reds')\n",
    "sns.clustermap(normalized_entropy_computational_scores/normalized_entropy_computational_scores.max(),figsize=(10,5),cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_transcripts_per_cell = pd.DataFrame()\n",
    "for segmentation, ads_seg in ads.items():\n",
    "    for donor, ad in ads_seg.items():\n",
    "        median_transcripts_per_cell.loc[segmentation,donor] = ad.uns['metrics_summary'].loc[0,'median_transcripts_per_cell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = normalized_entropy_computational_scores\n",
    "df2 = coexpr_scores\n",
    "\n",
    "plot_data = []\n",
    "for idx in df1.index:\n",
    "    for col in df1.columns:\n",
    "        plot_data.append({\n",
    "            'segmentation': idx,\n",
    "            'donors': col,\n",
    "            'normalized_entropy_computational_scores': df1.loc[idx, col],\n",
    "            'coexpr_scores': df2.loc[idx, col]\n",
    "        })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "sns.boxplot(plot_df,x='segmentation',y='coexpr_scores');plt.show()\n",
    "sns.boxplot(plot_df,x='segmentation',y='normalized_entropy_computational_scores')\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=plot_df,\n",
    "    x='normalized_entropy_computational_scores',  # x-axis: values from df1\n",
    "    y='coexpr_scores',  # y-axis: values from df2\n",
    "    hue='segmentation',  # color based on segmentation\n",
    "    style='donors',  # marker type based on donors\n",
    "    s=50  # marker size\n",
    ")\n",
    "\n",
    "# plt.title('Scatter Plot: df1 vs df2')\n",
    "# plt.xlabel('Values from df1')\n",
    "# plt.ylabel('Values from df2')\n",
    "plt.legend(title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find universal markers\n",
    "ad_sc_panel.var['n_cells'] = (ad_sc_panel.X>0).sum(0).A1\n",
    "ad_sc_panel.var['n_cells'].hist(bins=100)\n",
    "CC, X_downdonord, pos_, pos_rate_, mask_ = coexpression.coexpression(ad_sc_panel,target_count=None,min_cond_coex=0.)\n",
    "\n",
    "threshold = 0.01\n",
    "pos_rate_threshold = 0.01\n",
    "\n",
    "valid_genes = np.where(pos_rate > pos_rate_threshold)[0]\n",
    "\n",
    "gene_pairs_idx = np.vstack((CC.values<threshold).nonzero()).T\n",
    "gene_pairs_idx_u = pd.DataFrame(gene_pairs_idx)\n",
    "gene_pairs_idx_u['Key'] = gene_pairs_idx_u.apply(lambda row: tuple(sorted(row)), axis=1)\n",
    "gene_pairs_idx_u = gene_pairs_idx_u.drop_duplicates(subset='Key').drop(columns='Key')\n",
    "gene_pairs_idx_u = gene_pairs_idx_u[gene_pairs_idx_u.isin(valid_genes).sum(1)==2]\n",
    "gene_pairs_idx_u = gene_pairs_idx_u.values\n",
    "print(len(gene_pairs_idx_u))\n",
    "\n",
    "# Score xenium donors per gene\n",
    "# CC_computational_scores = {}\n",
    "# for segmentation in SEGMENTATIONS:\n",
    "#     for k,ad_ in ads[segmentation].items():\n",
    "#         CC_computational_scores[segmentation][k] = CC_computational[segmentation][k].values[gene_pairs_idx_u[:,0],gene_pairs_idx_u[:,1]].sum(1)\n",
    "\n",
    "# Score xenium donors per cell\n",
    "# CC_cells_score = coexpression.coexpression_cells_score_gene_pairs(CC_cells, gene_pairs_idx_u)\n",
    "\n",
    "# ad.obs['CC_cells_score'] = CC_cells_score\n",
    "# ad.obs['CC_cells_score'].hist(bins=100)\n",
    "\n",
    "# sc.set_figure_params(figsize=(10,10))\n",
    "# sc.pl.spatial(ad,color='CC_cells_score',spot_size=10,)\n",
    "# (ad.obs['CC_cells_score']>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
