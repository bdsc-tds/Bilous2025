{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "dask.config.set({\"dataframe.query-planning\": False})\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.extend(['../../scripts','../../scripts/xenium'])\n",
    "import readwrite\n",
    "import preprocessing\n",
    "\n",
    "cfg = readwrite.config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = args.panel\n",
    "out_file = args.out_file\n",
    "normalisation_method = args.normalisation_method\n",
    "layer = args.layer\n",
    "n_comps = args.n_comps\n",
    "n_neighbors = args.n_neighbors\n",
    "metric = args.metric\n",
    "min_dist = args.min_dist\n",
    "min_counts = args.min_counts\n",
    "min_features = args.min_features\n",
    "max_counts = args.max_counts\n",
    "max_features = args.max_features\n",
    "min_cells = args.min_cells\n",
    "\n",
    "\n",
    "segmentation = panel.parents[1].stem\n",
    "condition = panel.parents[0].stem\n",
    "\n",
    "# read xenium samples\n",
    "ads = {}\n",
    "for donor in (donors := panel.iterdir()):\n",
    "    for sample in (samples := donor.iterdir()):\n",
    "        print(sample)\n",
    "\n",
    "        k = (segmentation, condition, panel.stem, donor.stem, sample.stem)\n",
    "        sample_counts_path = sample / f\"{normalisation_method}/normalised_counts/{layer}.parquet\"\n",
    "        sample_idx_path = sample / f\"{normalisation_method}/normalised_counts/cells.parquet\"\n",
    "\n",
    "        ads[k] = sc.AnnData(pd.read_parquet(sample_counts_path))\n",
    "        if layer != \"scale_data\":  # no need to sparsify scale_data which is dense\n",
    "            ads[k].X = scipy.sparse.csr_matrix(ads[k].X)\n",
    "        ads[k].obs_names = pd.read_parquet(sample_idx_path).iloc[:, 0]\n",
    "\n",
    "\n",
    "# concatenate\n",
    "xenium_levels = [\"segmentation\", \"condition\", \"panel\", \"donor\", \"sample\"]\n",
    "for k in ads.keys():\n",
    "    for i, lvl in enumerate(xenium_levels):\n",
    "        ads[k].obs[lvl] = k[i]\n",
    "ad_merge = sc.concat(ads)\n",
    "\n",
    "# preprocess\n",
    "preprocessing.preprocess(\n",
    "    ad_merge,\n",
    "    normalize=False,\n",
    "    log1p=False,\n",
    "    scale=\"none\",\n",
    "    n_comps=n_comps,\n",
    "    metric=metric,\n",
    "    min_dist=min_dist,\n",
    "    n_neighbors=n_neighbors,\n",
    "    pca=True,\n",
    "    umap=True,\n",
    "    save_raw=False,\n",
    "    min_counts=None,\n",
    "    min_genes=None,\n",
    "    max_counts=None,\n",
    "    max_genes=None,\n",
    "    min_cells=None,\n",
    ")\n",
    "\n",
    "# save\n",
    "df_umap = pd.DataFrame(ad_merge.obsm[\"X_umap\"], index=ad_merge.obs_names, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "df_umap[xenium_levels] = ad_merge.obs[xenium_levels]\n",
    "\n",
    "df_umap.to_parquet(out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scib_metrics.benchmark import Benchmarker, BioConservation, BatchCorrection\n",
    "\n",
    "BATCH_KEY = \"sample\"\n",
    "CT_KEYS = [\"Level1\", \"Level2\", \"Level3\", \"Level4\", \"panel\", \"sample\"]\n",
    "# methods without batch key\n",
    "batchcor = BatchCorrection(\n",
    "    silhouette_batch=False,\n",
    "    ilisi_knn=True,\n",
    "    kbet_per_label=False,\n",
    "    graph_connectivity=False,\n",
    "    pcr_comparison=False,\n",
    ")\n",
    "\n",
    "biocons = BioConservation(\n",
    "    isolated_labels=False,\n",
    "    nmi_ari_cluster_labels_leiden=True,\n",
    "    nmi_ari_cluster_labels_kmeans=False,\n",
    "    silhouette_label=True,\n",
    "    clisi_knn=True,\n",
    ")\n",
    "\n",
    "for CT_KEY in CT_KEYS:\n",
    "    if pathlib.Path(f\"{out_dir}/scib_metrics_{CT_KEY}.csv\").exists():\n",
    "        continue\n",
    "    else:\n",
    "        bm = Benchmarker(\n",
    "            ad_refs,\n",
    "            batch_key=BATCH_KEY,\n",
    "            label_key=CT_KEY,\n",
    "            embedding_obsm_keys=LATENT_KEYS_SIMPLE,\n",
    "            bio_conservation_metrics=biocons,\n",
    "            batch_correction_metrics=batchcor,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        bm.benchmark()\n",
    "        bm.get_results(min_max_scale=False).to_csv(\n",
    "            f\"{out_dir}/scib_metrics_{CT_KEY}.csv\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
