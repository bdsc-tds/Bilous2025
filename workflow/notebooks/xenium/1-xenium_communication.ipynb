{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:504: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:505: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:506: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:507: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:508: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/numba/core/decorators.py:246: RuntimeWarning: nopython is set for njit and is ignored\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "dask.config.set({\"dataframe.query-planning\": False})\n",
    "\n",
    "import itertools\n",
    "import liana\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import gc\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import PyComplexHeatmap as pch\n",
    "from PyComplexHeatmap import HeatmapAnnotation, DotClustermapPlotter, anno_simple, anno_label\n",
    "\n",
    "sys.path.append(\"../../../workflow/scripts/\")\n",
    "import _utils\n",
    "import readwrite\n",
    "cfg = readwrite.config()\n",
    "sns.set_style('ticks')\n",
    "\n",
    "def remove_self_edges(knn_graph, labels, cti, ctj):\n",
    "    \"\"\"\n",
    "    Remove self edges from the knn graph for the given labels.\n",
    "    \"\"\"\n",
    "    # Find which nodes are labeled cti,ctj\n",
    "    is_cti = (labels == cti)\n",
    "    is_ctj = (labels == ctj)\n",
    "\n",
    "    # We'll zero out edges where both row and col are labeled cti or ctj\n",
    "    indptr = knn_graph.indptr\n",
    "    indices = knn_graph.indices\n",
    "    data = knn_graph.data\n",
    "\n",
    "    for i in range(knn_graph.shape[0]):\n",
    "        start, end = indptr[i], indptr[i+1]\n",
    "        neighbor_indices = indices[start:end]\n",
    "    \n",
    "        # Find neighbors that are also cti\n",
    "        if is_cti[i]:\n",
    "            mask = is_cti[neighbor_indices]\n",
    "            data[start:end][mask] = 0\n",
    "    \n",
    "        # Find neighbors that are also ctj\n",
    "        elif is_ctj[i]:\n",
    "            mask = is_ctj[neighbor_indices]\n",
    "            data[start:end][mask] = 0   \n",
    "\n",
    "    knn_graph.eliminate_zeros()\n",
    "    return knn_graph\n",
    "\n",
    "\n",
    "def ccc_score(\n",
    "    ad_cti_ctj,\n",
    "    knn_graph,\n",
    "    cti_receptor,\n",
    "    ctj_ligand,\n",
    "    labels_key,\n",
    "    cti,\n",
    "    correction_method,\n",
    "    k,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the CCC score for a given cell type.\n",
    "\n",
    "    Args:\n",
    "        ad_cti_ctj (scanpy.AnnData): AnnData object containing cell data.\n",
    "        knn_graph (scipy.sparse.csr_matrix): Connectivity graph.\n",
    "        cti_receptor (str): Name of the receptor gene in adata.var names.\n",
    "        ctj_ligand (str): Name of the ligand gene in adata.var names.\n",
    "        labels_key (str): Key in adata.obs for cell type labels.\n",
    "        cti (str): The specific receptor cell type label.\n",
    "        correction_method (str): Name of the correction method used.\n",
    "        k (tuple): Tuple representing the k value (e.g., (10,)).\n",
    "\n",
    "    Returns:\n",
    "        float: Mean product of receptor and neighbor ligand expression.\n",
    "    \"\"\"\n",
    "    X_receptor = ad_cti_ctj[:, cti_receptor].X.toarray().squeeze()\n",
    "    Y_ligand = ad_cti_ctj[:, ctj_ligand].X.toarray().squeeze()\n",
    "    cti_idx = np.where(ad_cti_ctj.obs[labels_key] == cti)[0]\n",
    "\n",
    "    indptr = knn_graph.indptr\n",
    "    indices = knn_graph.indices\n",
    "\n",
    "    ctj_ligand_product_mean = []\n",
    "    for i in cti_idx:\n",
    "        start, end = indptr[i], indptr[i+1]\n",
    "        neighbor_indices = indices[start:end]\n",
    "        ctj_ligand_product_mean.append((X_receptor[i] * Y_ligand[neighbor_indices]).mean())\n",
    "\n",
    "    return np.nanmean(ctj_ligand_product_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg paths\n",
    "xenium_processed_data_dir = Path(cfg['xenium_processed_data_dir'])\n",
    "xenium_count_correction_dir = Path(cfg['xenium_count_correction_dir'])\n",
    "xenium_std_seurat_analysis_dir = Path(cfg['xenium_std_seurat_analysis_dir'])\n",
    "xenium_cell_type_annotation_dir = Path(cfg['xenium_cell_type_annotation_dir'])\n",
    "results_dir = Path(cfg['results_dir'])\n",
    "palette_dir = Path(cfg['xenium_metadata_dir'])\n",
    "std_seurat_analysis_dir = Path(cfg['xenium_std_seurat_analysis_dir'])\n",
    "scrnaseq_processed_data_dir = Path(cfg['scrnaseq_processed_data_dir'])\n",
    "seurat_to_h5_dir = results_dir / 'seurat_to_h5'\n",
    "\n",
    "# Params\n",
    "signal_integrity_thresholds = [0.5, 0.7]\n",
    "correction_methods = ['raw', 'split_fully_purified', 'resolvi', 'resolvi_supervised']\n",
    "correction_methods += [f'ovrlpy_correction_{signal_integrity_threshold=}' for signal_integrity_threshold in signal_integrity_thresholds]\n",
    "num_samples = 30\n",
    "mixture_k = 50\n",
    "normalisation = 'lognorm'\n",
    "layer = 'data'\n",
    "reference = 'matched_reference_combo'\n",
    "method = 'rctd_class_aware'\n",
    "level = 'Level2.1'\n",
    "segmentation_palette = palette_dir / 'col_palette_segmentation.csv'\n",
    "count_correction_palette = palette_dir / 'col_palette_correction_method.csv'\n",
    "\n",
    "list_n_markers = [10, 20, 30, 40, 50]\n",
    "radius = 15\n",
    "top_n = 20\n",
    "markers_mode = 'diffexpr'\n",
    "\n",
    "xenium_levels = [\"segmentation\", \"condition\", \"panel\", \"donor\", \"sample\"]\n",
    "order = ['breast','chuvio','lung','5k']\n",
    "\n",
    "\n",
    "hue_segmentation = \"segmentation\"\n",
    "hue_segmentation_order = [\n",
    "    \"MM 0µm\",\n",
    "    \"MM\",\n",
    "    \"MM 15µm\",\n",
    "    \"0µm\",\n",
    "    \"5µm\",\n",
    "    \"15µm\",\n",
    "    \"Baysor\",\n",
    "    \"ProSeg\",\n",
    "    \"ProSeg mode\",\n",
    "    \"Segger\",\n",
    "]\n",
    "\n",
    "hue_correction = 'correction_method'\n",
    "hue_correction_order = [\n",
    "    'raw',\n",
    "    'ResolVI',\n",
    "    'ResolVI supervised',\n",
    "    'ovrlpy 0.5',\n",
    "    'ovrlpy 0.7',\n",
    "    'SPLIT',\n",
    "]\n",
    "\n",
    "\n",
    "rank_metrics = [\"logfoldchanges\", \"-log10pvals_x_logfoldchanges\", \"-log10pvals_x_sign_logfoldchanges\",\"mean_zscore\"]\n",
    "plot_metrics = ['hypergeometric_pvalue','NES',f\"n_hits_{top_n=}\",\"mean_zscore_pvalue\"]\n",
    "\n",
    "labels_key = level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load corrected counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenium_paths = {}\n",
    "xenium_annot_paths = {}\n",
    "\n",
    "for correction_method in correction_methods:\n",
    "    xenium_paths[correction_method] = {}\n",
    "    xenium_annot_paths[correction_method] = {}\n",
    "    \n",
    "    for segmentation in (segmentations := xenium_std_seurat_analysis_dir.iterdir()):\n",
    "        if segmentation.stem in ['proseg_mode','baysor','segger','10x_15um','10x_0um']:\n",
    "            continue\n",
    "        for condition in (conditions := segmentation.iterdir()): \n",
    "            for panel in (panels := condition.iterdir()):\n",
    "                for donor in (donors := panel.iterdir()):\n",
    "                    for sample in (samples := donor.iterdir()):\n",
    "\n",
    "                        k = (segmentation.stem,condition.stem,panel.stem,donor.stem,sample.stem)\n",
    "                        name = '/'.join(k)\n",
    "\n",
    "                        # raw samples\n",
    "                        if 'proseg' in segmentation.stem:\n",
    "                            k_proseg = ('proseg',condition.stem,panel.stem,donor.stem,sample.stem)\n",
    "                            name_proseg = '/'.join(k_proseg)\n",
    "                            sample_dir = xenium_processed_data_dir / f'{name_proseg}/raw_results'\n",
    "                        else:\n",
    "                            sample_dir = xenium_processed_data_dir / f'{name}/normalised_results/outs'\n",
    "\n",
    "                        sample_annotation = xenium_cell_type_annotation_dir / f'{name}/{normalisation}/reference_based/{reference}/{method}/{level}/single_cell/labels.parquet'\n",
    "                        \n",
    "                        if correction_method == 'raw':\n",
    "                            xenium_paths[correction_method][k] = sample_dir\n",
    "                            xenium_annot_paths[correction_method][k] = sample_annotation\n",
    "                        \n",
    "                        # corrected samples\n",
    "                        else:\n",
    "                            if correction_method == \"split_fully_purified\":\n",
    "                                name_corrected = f'{name}/{normalisation}/reference_based/{reference}/{method}/{level}/single_cell/split_fully_purified/'\n",
    "                                sample_corrected_counts_path = xenium_count_correction_dir / f\"{name_corrected}/corrected_counts.h5\"\n",
    "\n",
    "                            else:\n",
    "                                if correction_method == \"resolvi\":\n",
    "                                    name_corrected = f'{name}/{mixture_k=}/{num_samples=}/'\n",
    "                                elif correction_method == \"resolvi_supervised\":\n",
    "                                    name_corrected = f'{name}/{normalisation}/reference_based/{reference}/{method}/{level}/{mixture_k=}/{num_samples=}'\n",
    "                                elif \"ovrlpy\" in correction_method:\n",
    "                                    name_corrected = f'{name}'\n",
    "\n",
    "                                sample_corrected_counts_path = results_dir / f\"{correction_method}/{name_corrected}/corrected_counts.h5\"\n",
    "                            sample_normalised_counts = xenium_std_seurat_analysis_dir / f'{name}/{normalisation}/normalised_counts/{layer}.parquet'\n",
    "                            sample_idx = xenium_std_seurat_analysis_dir / f'{name}/{normalisation}/normalised_counts/cells.parquet'\n",
    "\n",
    "                            xenium_paths[correction_method][k] = sample_corrected_counts_path\n",
    "\n",
    "\n",
    "ads = readwrite.read_count_correction_samples(xenium_paths,correction_methods[1:])\n",
    "ads['raw'] = readwrite.read_xenium_samples(xenium_paths['raw'],anndata=True,transcripts=False,max_workers=6)\n",
    "\n",
    "# fix obs names for proseg expected, load cell types\n",
    "# filter out cells without labels (this will apply QC thresholds as well since annotation is done after QC)\n",
    "for correction_method in correction_methods:\n",
    "    for k, ad in ads[correction_method].items():\n",
    "        if ad is not None:\n",
    "\n",
    "            if correction_method == 'raw':\n",
    "                if k[0] == \"proseg_expected\": \n",
    "                    ad.obs_names = ad.obs_names.astype(str)\n",
    "                    ad.obs_names = \"proseg-\" + ad.obs_names\n",
    "\n",
    "                # filter cells and read labels for raw\n",
    "                ad.obs[labels_key] = pd.read_parquet(xenium_annot_paths['raw'][k]).set_index(\"cell_id\").iloc[:, 0]\n",
    "                \n",
    "\n",
    "                ad = ad[ad.obs[labels_key].notna()]\n",
    "                if labels_key == \"Level2.1\":\n",
    "                    # for custom Level2.1, simplify subtypes\n",
    "                    ad.obs.loc[ad.obs[labels_key].str.contains(\"malignant\"), labels_key] = \"malignant cell\"\n",
    "                    ad.obs.loc[ad.obs[labels_key].str.contains(\"T cell\"), labels_key] = \"T cell\"     \n",
    "                    \n",
    "                # remove tissue from cell type name\n",
    "                ad.obs[labels_key] = ad.obs[labels_key].str.replace(r\" of .+\", \"\", regex=True)\n",
    "                \n",
    "\n",
    "            # filter cells and add labels from raw\n",
    "            if correction_method != 'raw':\n",
    "                ad.obs[labels_key] = ads['raw'][k].obs[labels_key]\n",
    "                obs_names_idx = [c for c in ads['raw'][k].obs_names if c in ad.obs_names]\n",
    "                ad = ad[obs_names_idx]\n",
    "                ad.obsm['spatial'] = ads['raw'][k][obs_names_idx].obsm['spatial']\n",
    "\n",
    "            # normalize\n",
    "            sc.pp.normalize_total(ad)\n",
    "            sc.pp.log1p(ad)\n",
    "\n",
    "            # store\n",
    "            ads[correction_method][k] = ad\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check communication for cti with ctj neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cti = 'T cell'\n",
    "ctj = 'malignant cell'\n",
    "radius = 15\n",
    "obsm = 'spatial'\n",
    "\n",
    "df_lr=liana.resource.select_resource('consensus')\n",
    "df_lr_pd1_reverse = df_lr[(df_lr =='PDCD1').any(axis=1) | (df_lr == 'CD274').any(axis=1)]\n",
    "df_lr_pd1_reverse.columns = ['receptor','ligand']\n",
    "df_lr = pd.concat((df_lr,df_lr_pd1_reverse))\n",
    "\n",
    "lrdatas = {}\n",
    "df_plot_liana = {}\n",
    "df_plot_expr_cti = {}\n",
    "df_plot_expr_ctj = {}\n",
    "df_ccc_score = {}\n",
    "for correction_method in correction_methods:\n",
    "    lrdatas[correction_method] = {}\n",
    "\n",
    "    for k, ad in ads[correction_method].items():\n",
    "        if k[1] != 'NSCLC' or k[0] not in ['proseg_expected','10x_5um'] or k[2] != 'lung':\n",
    "            continue\n",
    "\n",
    "        if ad is not None:\n",
    "\n",
    "            if not np.all(np.isin([cti,ctj], ad.obs[labels_key].unique())):\n",
    "                continue\n",
    "\n",
    "            print(correction_method,k)\n",
    "\n",
    "\n",
    "            # subset to cti ctj\n",
    "            ad_cti_ctj = ad[ad.obs[labels_key].isin([cti, ctj])].copy()\n",
    "\n",
    "            # get kNN graph\n",
    "            knnlabels, knndis, knnidx, knn_graph = _utils.get_knn_labels(\n",
    "                ad_cti_ctj,radius=radius,\n",
    "                label_key=labels_key,obsm=obsm,\n",
    "                return_sparse_neighbors=True)\n",
    "                \n",
    "            ad_cti_ctj.obsp[f'{obsm}_connectivities'] = knn_graph\n",
    "            ad_cti_ctj.obs[f\"has_{cti}_neighbor\"] = knnlabels[cti] > 0\n",
    "            ad_cti_ctj.obs[f\"has_{ctj}_neighbor\"] = knnlabels[ctj] > 0\n",
    "\n",
    "\n",
    "            if (ad_cti_ctj.obs[f\"has_{ctj}_neighbor\"]).sum() < 30 or (~ad_cti_ctj.obs[f\"has_{ctj}_neighbor\"]).sum() < 30:\n",
    "                print(f\"Not enough cells from each class to test {cti} with {ctj} neighbors\")\n",
    "                continue\n",
    "            \n",
    "            ad_cti_ctj.obsp[f'{obsm}_connectivities'] = remove_self_edges(ad_cti_ctj.obsp[f'{obsm}_connectivities'], \n",
    "                                                                          ad_cti_ctj.obs[labels_key].values, cti, ctj)\n",
    "            # liana CCC score\n",
    "            lrdata = liana.mt.sp.bivariate(\n",
    "                ad_cti_ctj,\n",
    "                connectivity_key = f'{obsm}_connectivities',\n",
    "                resource=df_lr, # NOTE: uses HUMAN gene symbols!\n",
    "                local_name='cosine', # Name of the function\n",
    "                global_name=None,\n",
    "                n_perms=1, # Number of permutations to calculate a p-value\n",
    "                mask_negatives=True, # Whether to mask LowLow/NegativeNegative interactions\n",
    "                add_categories=False, # Whether to add local categories to the results\n",
    "                nz_prop=0.0, # Minimum expr. proportion for ligands/receptors and their subunits\n",
    "                use_raw=False,\n",
    "                verbose=False\n",
    "                )\n",
    "\n",
    "            # custom CCC score\n",
    "            for ctj_ligand, cti_receptor in df_lr.values:\n",
    "                if ctj_ligand in ad_cti_ctj.var_names and cti_receptor in ad_cti_ctj.var_names:\n",
    "                    df_ccc_score[correction_method,*k,f'{ctj_ligand}_{cti_receptor}'] = ccc_score(\n",
    "                            ad_cti_ctj,\n",
    "                            knn_graph,\n",
    "                            cti_receptor,\n",
    "                            ctj_ligand,\n",
    "                            labels_key,\n",
    "                            cti,\n",
    "                            correction_method,\n",
    "                            k,\n",
    "                        )\n",
    "\n",
    "            lrdata.var[f\"has_{ctj}_neighbor_mean\"] = lrdata[(lrdata.obs[labels_key] == cti) & (lrdata.obs[f\"has_{ctj}_neighbor\"])].X.mean(0).A1\n",
    "            lrdata.var[f\"has_no_{ctj}_neighbor_mean\"] = lrdata[(lrdata.obs[labels_key] == cti) & (~lrdata.obs[f\"has_{ctj}_neighbor\"])].X.mean(0).A1\n",
    "\n",
    "            ad_cti_ctj.var[f\"has_{ctj}_neighbor_mean\"] = ad_cti_ctj[(ad_cti_ctj.obs[labels_key] == cti) & (ad_cti_ctj.obs[f\"has_{ctj}_neighbor\"])].X.mean(0).A1\n",
    "            ad_cti_ctj.var[f\"has_no_{ctj}_neighbor_mean\"] = ad_cti_ctj[(ad_cti_ctj.obs[labels_key] == cti) & (~ad_cti_ctj.obs[f\"has_{ctj}_neighbor\"])].X.mean(0).A1\n",
    "\n",
    "            ad_cti_ctj.var[f\"has_{cti}_neighbor_mean\"] = ad_cti_ctj[(ad_cti_ctj.obs[labels_key] == ctj) & (ad_cti_ctj.obs[f\"has_{cti}_neighbor\"])].X.mean(0).A1\n",
    "            ad_cti_ctj.var[f\"has_no_{cti}_neighbor_mean\"] = ad_cti_ctj[(ad_cti_ctj.obs[labels_key] == ctj) & (~ad_cti_ctj.obs[f\"has_{cti}_neighbor\"])].X.mean(0).A1\n",
    "\n",
    "            lrdatas[correction_method][k] = lrdata\n",
    "            df_plot_liana[correction_method,*k] = lrdata.var[[f\"has_{ctj}_neighbor_mean\",f\"has_no_{ctj}_neighbor_mean\"]]\n",
    "            df_plot_expr_cti[correction_method,*k] = ad_cti_ctj.var[[f\"has_{ctj}_neighbor_mean\",f\"has_no_{ctj}_neighbor_mean\"]]\n",
    "            df_plot_expr_ctj[correction_method,*k] = ad_cti_ctj.var[[f\"has_{cti}_neighbor_mean\",f\"has_no_{cti}_neighbor_mean\"]]\n",
    "\n",
    "id_vars = ['correction_method'] + xenium_levels\n",
    "\n",
    "df_plot_liana = pd.concat(df_plot_liana).reset_index()\n",
    "df_plot_liana.columns = id_vars + df_plot_liana.columns[len(id_vars):].tolist()\n",
    "df_plot_liana = df_plot_liana.melt(id_vars=id_vars+['interaction'])\n",
    "_utils.rename_methods(df_plot_liana)\n",
    "df_plot_liana['ID'] = df_plot_liana[id_vars+['variable']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "df_ccc_score = pd.Series(df_ccc_score).reset_index()\n",
    "df_ccc_score.columns = id_vars + [\"interaction\",\"ccc_score\"]\n",
    "_utils.rename_methods(df_ccc_score)\n",
    "df_ccc_score['ID'] = df_ccc_score[id_vars].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "dfs_plot_expr = {(cti,ctj):df_plot_expr_cti,(ctj,cti):df_plot_expr_ctj}\n",
    "for ct, df_ in dfs_plot_expr.items():\n",
    "    df_ = pd.concat(df_).reset_index()\n",
    "    df_.columns = id_vars + ['gene'] + df_.columns[len(id_vars)+1:].tolist()\n",
    "    df_ = df_.melt(id_vars=id_vars+['gene'])\n",
    "    _utils.rename_methods(df_)\n",
    "    df_['ID'] = df_[id_vars+['variable']].astype(str).agg('-'.join, axis=1)\n",
    "    dfs_plot_expr[ct]=df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap liana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_metric = 'value'\n",
    "list_ref_panel = ['lung']\n",
    "list_ref_segmentation = ['5µm','ProSeg']\n",
    "\n",
    "\n",
    "Path('../../scratch/heatmaps_ccc/').mkdir(parents=True, exist_ok=True)\n",
    "for ref_panel, ref_segmentation, in itertools.product(list_ref_panel,list_ref_segmentation):\n",
    "\n",
    "    if ref_panel == '5k' and ref_segmentation == '5µm':\n",
    "        ref_segmentation = 'MM'\n",
    "    df_plot_sub = df_plot_liana.query(\"segmentation == @ref_segmentation and panel == @ref_panel\")\n",
    "    df_plot_sub = df_plot_sub[df_plot_sub['variable']==f'has_{ctj}_neighbor_mean']\n",
    "\n",
    "    df_plot_sub[rank_metric] = df_plot_sub[rank_metric]+np.random.normal(0,1e-10,len(df_plot_sub))\n",
    "    ### heatmap row/col labels\n",
    "    df_col=df_plot_sub[['correction_method','segmentation','panel','variable','ID']].drop_duplicates()#.to_frame()\n",
    "    df_col.set_index('ID',inplace=True)\n",
    "\n",
    "    col_ha = HeatmapAnnotation(\n",
    "        # variable=anno_simple(df_col['variable'], legend=True,add_text=True),\n",
    "        correction_method=anno_simple(df_col['correction_method'], legend=True,add_text=True),\n",
    "        # panel=anno_simple(df_col['panel'], cmap='Dark2',legend=False,add_text=True),\n",
    "        # segmentation=anno_simple(df_col['segmentation'], cmap='Set1',legend=False,add_text=True),\n",
    "        verbose=0,label_side='left')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    cm = DotClustermapPlotter(\n",
    "        data=df_plot_sub, \n",
    "        x='ID',y='interaction',value=rank_metric,c=rank_metric,\n",
    "        s=1,\n",
    "        row_cluster=True,col_cluster=False,\n",
    "        #hue='EnrichType', \n",
    "        #cmap={'Enrich':'RdYlGn_r','Depletion':'coolwarm_r'},\n",
    "        #colors={'Enrich':'red','Depletion':'blue'},\n",
    "        #marker={'Enrich':'^','Depletion':'v'},\n",
    "        top_annotation=col_ha,\n",
    "        # right_annotation=row_ha,\n",
    "        # col_split=df_col['variable'],\n",
    "        # col_split_order=['has_malignant cell_neighbor_mean','has_no_malignant cell_neighbor_mean'],\n",
    "        col_split=df_col['correction_method'],\n",
    "        col_split_order=hue_correction_order,\n",
    "        # row_split=df_row['gene_label'], \n",
    "        # row_split_order=[k for k in gene_labels.keys() if k in df_row['gene_label'].unique()],\n",
    "\n",
    "        cmap='Purples',#center=0,\n",
    "        col_split_gap=0,row_split_gap=5,\n",
    "        show_rownames=True,show_colnames=False,row_dendrogram=False,\n",
    "        verbose=0,legend_gap=10,linewidths=.1,spines=True,\n",
    "        # vmin=-0.04,vmax=0.04,\n",
    "        vmax=np.percentile(df_plot_sub[rank_metric],95),\n",
    "        ) #if the size of dot in legend is too large, use alpha to control, for example: alpha=0.8\n",
    "\n",
    "    plt.savefig(f\"../../scratch/heatmaps_ccc/heatmap_ccc_{ref_panel=}_{ref_segmentation=}.png\",bbox_inches='tight',dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap custom CCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_metric = 'ccc_score'\n",
    "list_ref_panel = ['lung']\n",
    "list_ref_segmentation = ['5µm','ProSeg']\n",
    "u_genes = np.unique(df_lr.values.flatten())\n",
    "\n",
    "for (cti_,ctj_), df_ in dfs_plot_expr.items():\n",
    "    df_plot_expr_lr = df_[df_['gene'].isin(u_genes)]\n",
    "\n",
    "    Path('../../scratch/heatmaps_ccc/').mkdir(parents=True, exist_ok=True)\n",
    "    for ref_panel, ref_segmentation, in itertools.product(list_ref_panel,list_ref_segmentation):\n",
    "\n",
    "        if ref_panel == '5k' and ref_segmentation == '5µm':\n",
    "            ref_segmentation = 'MM'\n",
    "        df_plot_sub = df_plot_expr_lr.query(\"segmentation == @ref_segmentation and panel == @ref_panel\")\n",
    "\n",
    "        df_plot_sub[rank_metric] = df_plot_sub[rank_metric]+np.random.normal(0,1e-10,len(df_plot_sub))\n",
    "        ### heatmap row/col labels\n",
    "        df_col=df_plot_sub[['correction_method','segmentation','panel','variable','ID']].drop_duplicates()#.to_frame()\n",
    "        df_col.set_index('ID',inplace=True)\n",
    "\n",
    "        col_ha = HeatmapAnnotation(\n",
    "            variable=anno_simple(df_col['variable'], legend=True,add_text=True),\n",
    "            correction_method=anno_simple(df_col['correction_method'], legend=True,add_text=True),\n",
    "            # panel=anno_simple(df_col['panel'], cmap='Dark2',legend=False,add_text=True),\n",
    "            # segmentation=anno_simple(df_col['segmentation'], cmap='Set1',legend=False,add_text=True),\n",
    "            verbose=0,label_side='left')\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(15, 25))\n",
    "        cm = DotClustermapPlotter(\n",
    "            data=df_plot_sub, \n",
    "            x='ID',y='gene',value=rank_metric,c=rank_metric,\n",
    "            s=None,\n",
    "            row_cluster=True,col_cluster=False,\n",
    "            #hue='EnrichType', \n",
    "            #cmap={'Enrich':'RdYlGn_r','Depletion':'coolwarm_r'},\n",
    "            #colors={'Enrich':'red','Depletion':'blue'},\n",
    "            #marker={'Enrich':'^','Depletion':'v'},\n",
    "            top_annotation=col_ha,\n",
    "            # right_annotation=row_ha,\n",
    "            col_split=df_col['variable'],\n",
    "            col_split_order=[f'has_{ctj_}_neighbor_mean',f'has_no_{ctj_}_neighbor_mean'],\n",
    "            # row_split=df_row['gene_label'], \n",
    "            # row_split_order=[k for k in gene_labels.keys() if k in df_row['gene_label'].unique()],\n",
    "\n",
    "            cmap='Purples',#center=0,\n",
    "            col_split_gap=0,row_split_gap=5,\n",
    "            show_rownames=True,show_colnames=False,row_dendrogram=False,\n",
    "            verbose=0,legend_gap=10,linewidths=.1,spines=True,\n",
    "            # vmin=-0.04,vmax=0.04,\n",
    "            vmin=0.0,vmax=1,\n",
    "            ) #if the size of dot in legend is too large, use alpha to control, for example: alpha=0.8\n",
    "\n",
    "        plt.savefig(f\"../../scratch/heatmaps_ccc/heatmap_ccc_expr_{cti_}_{ref_panel=}_{ref_segmentation=}.png\",bbox_inches='tight',dpi=300)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
